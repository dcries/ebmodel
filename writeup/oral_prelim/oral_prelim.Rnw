\documentclass[handout]{beamer}

\usetheme{AnnArbor}
\usecolortheme{beaver}

%\usepackage{caption}
%\captionsetup{font=footnotesize,labelfont=footnotesize}
\setbeamerfont{caption}{series=\normalfont,size=\fontsize{5}{5}} 

\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}
\usepackage{multicol}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{enumerate items}[default]
\setbeamertemplate{enumerate subitem}{\alph{enumii}.}
\setbeamertemplate{enumerate subsubitem}{\roman{enumiii}.}
\setkeys{Gin}{width=0.6\textwidth}

\title{Modeling of Energy Balance and Physical Activity Data}
\author[Danny Ries]{Danny Ries}
\institute[Iowa State]{Iowa State University}
\date{\today}

\newcommand{\mG}{\mathrm{\Gamma}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\mySigma}{\mathrm{\Sigma}}
\newcommand{\ind}{\stackrel{ind}{\sim}}


\begin{document}

%\section{Temp??} \begin{comment}

<<options, results='hide', echo=FALSE>>=
# These are only needed for the slides
# No need to run if you are just running the R code
opts_chunk$set(fig.width=7, 
               fig.height=5, 
               out.width='.8\\linewidth', 
               fig.align='center', 
               size='tiny',
               echo=FALSE)
options(width=100)
@

<<libraries, echo=FALSE, message=FALSE, warning=FALSE>>=
setwd("U:\\Desktop\\research\\data")
#setwd("C:\\Users\\Danny\\Box Sync\\research\\data")
eb <- read.csv("C:\\Users\\dcries\\github\\ebmodel\\data\\ebs_2_23.csv")
library(ggplot2)
library(reshape2)
library(dplyr)
library(lubridate)
source('C:\\Users\\dcries\\github\\ebmodel\\base_fcn.R', echo=FALSE)

@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\frame{\maketitle}

\section{Application Motivation}
%\subsection{Motivation}
%--------
\begin{frame}
\frametitle{The Obesity Epidemic}

Over 35\% of Americans are obese, and over  75\% of men are either overweight or obese. Obesity is linked to many different medical, psychological, emotional, and economic effects such as:
\begin{itemize}
\begin{multicols}{2}
\item
Type 2 Diabetes
\item
Coronary Heart Disease
\item
High Blood Pressure
\item 
Clinical Depression
\columnbreak
\item
Anxiety
\item 
Increased Health Care Costs
\item
Lost Wages
\item
Discrimination
\end{multicols}
\end{itemize}

\end{frame}

%-----------





%-----------
\begin{frame}
\frametitle{2 Remedies to aid in Obesity Research}
\begin{enumerate}
\item
Accurately and efficiently measure Energy Intake (EI)

\vspace{0.2cm}

\item
Assess compliance to \emph{2008 Physical Activity Guidelines}
\end{enumerate}

%\vspace{0.2cm}

%A common issue here is we are dealing with 

\end{frame}
%-----------

\section{Modeling EB}
\subsection{Introduction}
%-------------------
\begin{frame}
To address the difficulty in measuring EI:

\vspace{0.4cm}
\huge Bayesian Semi-Parametric Energy Balance Measurement Error Model

\end{frame}
%------------------


%----------
\begin{frame}
\frametitle{The ``Fatal Flaw in Obesity Research"}
It has been said the ``Fatal Flaw in Obesity Research" is our inability to accurately measure how much someone eats (EI) in free living situations

\begin{itemize}
\item
Current measures of EI; ie. self report, are clouded with (measurement) error \\
\item
Garbage in Garbage out \\
\item
Tough to understand dietary trends over the years \\
\item
Cannot measure adherence to clinically prescribed interventions \\
\end{itemize}

This error in measurement extends to EE and body composition, albeit not nearly as severe

\end{frame}

%---------------

\subsection{Energy Balance}
%-----------
\begin{frame}
\frametitle{Modeling Energy Balance}

\begin{block}{Energy Balance}
The application of the first law of thermodynamics to nutrition/exercise science: \\
Change in Energy Stores ($\Delta$ES) = Energy Intake (EI) - Energy Expenditure (EE)
\end{block}

where $\Delta$ES $= c_1 \frac{\Delta FM}{\Delta T } + c_2 \frac{\Delta FFM}{\Delta T}$  



\vspace{0.3cm}

We are now in a situation where we must measure both EE and $\Delta$ES in order to calculate EI \\

$\rightarrow$ But gold standard measures (albeit very costly) and cheap measurements for both exist! 


\end{frame}
%-----------

%-----------
% \begin{frame}
% \frametitle{Modeling Energy Balance Cont.}
% We are now in a situation where we must measure both EE and $\Delta$ES in order to calculate EI \\
% $\rightarrow$ But gold standard measures for both exist!
% 
% \vspace{0.3cm}
% 
% In a world of unlimited resources, researchers needing EI for individuals could use gold standard measures of EE and $\Delta$ES and use simple measurement error models\\
% 
% \vspace{0.3cm}
% 
% Unfortunately,\\
% DLW $\sim$ \$500/person \\
% DXA $\sim$ \$100/person
% 
% \end{frame}
% %----------

%----------
\begin{frame}

\begin{block}{Research Goal}
Create a joint statistical measurement model for gold standard and cheap measurements of both EE and $\Delta$ES in order to develop calibration equations for cheap measurements.\\
\end{block}

\vspace{0.4cm}

\begin{itemize}
\item
This will allow future research to calibrate cheaper measurements (when gold standard measures aren't used) and thus eliminate known biases
\item
Lots of research has been done for calibrating and evaluating measurement error for EI, some for EE, and little for $\Delta$ES
\item
To the best of our knowledge, no research has been done in evaluating the measurement error and calibrating measurements jointly via the Energy Balance principle
\end{itemize}


\end{frame}
%----------


\subsection{Exploratory Analysis}

%---------
\begin{frame}
\frametitle{Energy Balance Study}
The Energy Balance Study (EBS) was conducted 2011-2012 at the University of South Carolina
\begin{itemize}
\item
430 male and females aged 20-35 \\
\item
5 DXA scans, one every 3 months
\item
Sensewear Armband measuring EE every 3 months (averaged across 10 days)
\item
Subset of 119 participants receieved DLW at end of 12 months, with additional DXA scan
\item
Demographic variables
\end{itemize}

\vspace{0.2cm}

Although these data don't have perfect replicates, it provides a baseline to start our modeling of measurement error in Energy Balance


\end{frame}
%--------

%--------
\begin{frame}
%\frametitle{Checking Normality of Measurement Errors}

\begin{figure}
\centering
\includegraphics[width=8cm,height=3cm]{dxa_qq.pdf}
\caption{{Differenced DXA $\Delta$ES, Females left, Males right}}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=8cm,height=3cm]{swa_qq.pdf}
\caption{Differenced SWA  EE , Females left, Males right}
\end{figure}


\end{frame}
%--------

%--------
\begin{frame}
\frametitle{Na{\"i}ve Check for Biases}
It seems reasonable that cheap measurement tools could be affected by factors other than the \emph{truth}, ie. demographics \\

\vspace{0.3cm}

$\rightarrow$ Fit the following multiple regression model with the subset data from EBS\\
SWA EE = $\beta_0 + \beta_1$DLW EE + $\beta_z$' Demographic Variables + $\epsilon$ \\




\end{frame}
%-------

%-------
\begin{frame}

\begin{table} \centering 
  \caption{Regression of Sensewear Armband EE on DLW EE, Age, BMI, Gender using EBS data. Results show systematic biases could exist in cheap EE measurements.} 
\begin{tabular}{l|ccc}
\hline
Coefficient & Estimate & Std Error & P-value \\
\hline
Intercept & 878.422 & 154.113 & $<$0.0001 \\
DLW EE & 0.558 & 0.040 & $<$0.0001 \\
Age & -7.351 & 3.999 & 0.0676 \\
Male & 305.582 & 43.258 & $<$0.0001 \\
BMI & 14.146 & 3.988 & 0.0004 \\
\hline
\end{tabular} 
\end{table} 
\end{frame}
%-------


\subsection{Modeling}

%-------
\begin{frame}
\frametitle{Notation}
let $i$ represent individual and $j$ represent replicate number \\

\vspace{0.3cm}

Observable:
\begin{itemize}
\item
$W_{ij}^{EE}$ and $W_{ij}^{\Delta ES}$ represent gold standard measures of EE and $\Delta$ES
\item
$Y_{ij}^{EE}$ and $Y_{ij}^{\Delta ES}$ represent cheap measures of EE and $\Delta$ES
\item
$Z_i$ represent a $k\times 1$ vector of error free covariates
\end{itemize}

\vspace{0.2cm}

Latent:
\begin{itemize}
\item
$X_{i}^{EE}$ and $X_{i}^{\Delta ES}$ represent \emph{usual} EE and $\Delta$ES

\end{itemize}

\end{frame}
%-------


%-------
\begin{frame}
\frametitle{Independence Assumptions}
Given $X_i^{EE}, Z_i$

\begin{itemize}
\item
$Y^{EE}_{ij}$ are mutually independent for all $i,j$ \\
\item
$W_{ij}^{EE}$ are mutually independent for all $i,j$ \\
\item
$Y_{ij}^{EE}$ is independent of $W_{ij}^{EE}$ for all $i,j$ \\
\item
$Y_{ij}^{EE}$ is independent of $W_{ij}^{\Delta ES}$ and $Y_{ij}^{\Delta ES}$ for all $i,j$ \\
\item
$W_{ij}^{EE}$ is independent of $W_{ij}^{\Delta ES}$ and $Y_{ij}^{\Delta ES}$ for all $i,j$ \\
\end{itemize}

\vspace{0.2cm}

Same assumptions hold for reverse case (replace EE with $\Delta$ES and $\Delta$ES with EE)


\end{frame}
%-------


%-------
\begin{frame}
\frametitle{Model for Observed Variables}


\begin{align*}
  Y_{ij}^{EE} &= m_{ee}(X_i^{EE} ,Z_i) + \epsilon_{ij}^{EE}   \\
   %& \\
  %
  Y_{ij}^{\Delta ES} &= m_{es}(X_i^{\Delta ES} ,Z_i) + \epsilon_{ij}^{\Delta ES} \\
  %
     %& \\
  W_{ij}^{EE} &= X_i^{EE}  + \nu_{ij}^{EE} \\
  %
     %& \\
  W_{ij}^{\Delta ES} &= X_i^{\Delta ES}  + \nu_{ij}^{\Delta ES}
\end{align*}

\vspace{0.5cm}
$E(\epsilon_{ij}^{EE}) = E(\epsilon_{ij}^{\Delta ES}) = E(\nu_{ij}^{EE}) = E(\nu_{ij}^{\Delta ES}) = 0$

\end{frame}
%------

%----------------
% \begin{frame}
% \frametitle{Joint Likelihood}
% %Using conditional independence assumptions, our joint probability model for our observed data can be represented by:
% 
% \scalebox{0.67}{\parbox{.5\linewidth}{%
% \begin{align*}
%   \begin{split}
%   L_i(\boldsymbol{\theta}) &= \prod_{j=1}^{J} f(W_{ij}^{EE},W_{ij}^{\Delta ES}, Y_{ij}^{EE},Y_{ij}^{\Delta ES}|Z_i,\boldsymbol{\theta})  \\
%    &=  \int_{\mathcal{X}_{es}} \int_{\mathcal{X}_{ee}} \prod_{j=1}^{J} f({ W_{ij}^{EE},W_{ij}^{\Delta ES}, Y_{ij}^{EE},Y_{ij}^{\Delta ES}, X_i^{EE}, X_i^{\Delta ES}|Z_i},\boldsymbol{\theta}) d{ X_i^{EE}} d{ X_i^{\Delta ES}} \\
%   %
%     &= \prod_{j=1}^{J} \int_{\mathcal{X}_{es}} \int_{\mathcal{X}_{ee}} f({ W_{ij}^{EE}|X_i^{EE},X_i^{\Delta ES},Z_i},\boldsymbol{\theta_{wee}}) f({ W_{ij}^{\Delta ES}|X_i^{EE},X_i^{\Delta ES},Z_i},\boldsymbol{\theta_{wes}}) \times\\
%   & f({ Y_{ij}^{EE}|X_i^{EE},X_i^{\Delta ES},Z_i},\boldsymbol{\theta_{yee}}) f({ Y_{ij}^{\Delta ES}|X_i^{EE},X_i^{\Delta ES},Z_i},\boldsymbol{\theta_{yes}})  
%    f({ X_i^{EE}, X_i^{\Delta ES}|Z_i},\boldsymbol{\theta_x}) d{ X_i^{EE}} d{ X_i^{\Delta ES}} \\
%   %
%   &= \prod_{j=1}^{J} \int_{\mathcal{X}_{es}} \int_{\mathcal{X}_{ee}} f({ W_{ij}^{EE}|X_i^{EE},Z_i},\boldsymbol{\theta_{wee}}) f({ W_{ij}^{\Delta ES}|X_i^{\Delta ES},Z_i},\boldsymbol{\theta_{wes}}) \times\\
%   & f({ Y_{ij}^{EE}|X_i^{EE},Z_i},\boldsymbol{\theta_{yee}}) f({ Y_{ij}^{\Delta ES}|X_i^{\Delta ES},Z_i},\boldsymbol{\theta_{yes}})  
%    f({ X_i^{EE}, X_i^{\Delta ES}|Z_i},\boldsymbol{\theta_x}) d{ X_i^{EE}} d{ X_i^{\Delta ES}} 
%   \end{split}
%   & \\
%   & \\
%   L(\boldsymbol{\theta}) &= \prod_{i=1}^{n}  L_i(\boldsymbol{\theta}) 
% \end{align*}
% }}
% 
% 
% 
% \end{frame}
% 
%-------------


%-------
\begin{frame}
\frametitle{Na{\"i}ve Model}

The Na{\"i}ve Model assumes no measurement error in gold standard measurements (Note the part for EE is the same as what we used for our exploratory analysis) \\

\vspace{1cm}

\begin{align*}
  (Y_{ij}^{EE} | W_{ij}^{EE},Z_i,\boldsymbol{\theta_{yee}}) &\overset{ind}{\sim} N(\beta_{0,ee} + \beta_{1,ee}W_{ij}^{EE}+ \boldsymbol{\gamma_{ee}}Z_i,\sigma_{\epsilon^{EE}}^2) \\
  (Y_{ij}^{\Delta ES} | W_{ij}^{\Delta ES},Z_i,\boldsymbol{\theta_{yes}}) &\overset{ind}{\sim} N(\beta_{0,es} + \beta_{1,es}W_{ij}^{\Delta ES}+ \boldsymbol{\gamma_{es}}Z_i,\sigma_{\epsilon^{\Delta ES}}^2)
\end{align*}

\end{frame}
%-------


%-------
\begin{frame}
\frametitle{Linear Measurement Error Model}
This is a basic modification to the Na{\"i}ve model when there is measurement error in a covariate

\begin{align*}
  (Y_{ij}^{EE}|X_i^{EE}, Z_i,\boldsymbol{\theta_{yee}}) &\overset{ind}{\sim} N(\beta_{0,ee} + \beta_{1,ee}X_i^{EE} + \boldsymbol{\gamma_{ee}}Z_i, \sigma_{\epsilon_{EE}}^2) \\
  (Y_{ij}^{\Delta ES}|X_i^{\Delta ES}, Z_i,\boldsymbol{\theta_{yes}}) &\overset{ind}{\sim} N(\beta_{0,es} + \beta_{1,es}X_i^{\Delta ES} +  \boldsymbol{\gamma_{es}}Z_i, \sigma_{\epsilon_{\Delta ES}}^2) \\
  (W_{ij}^{EE}|X_i^{EE}, Z_i,\boldsymbol{\theta_{wee}}) &\overset{ind}{\sim} N(X_i^{EE}, \sigma_{\nu_{EE}}^2 ) \\
  (W_{ij}^{\Delta ES}|X_i^{\Delta ES}, Z_i,\boldsymbol{\theta_{wes}}) &\overset{ind}{\sim} N(X_i^{\Delta ES}, \sigma_{\nu_{\Delta ES}}^2 )  \\
  (X_i^{EE},X_i^{\Delta ES}|\theta_X) &\overset{ind}{\sim} N\left(
  \begin{bmatrix}
  \mu_{EE}\\
  \mu_{\Delta ES}
  \end{bmatrix}
  , \Sigma_X
  \right)
\end{align*}

\end{frame}
%-------


%------
\begin{frame}
\frametitle{Extending the Linear Model}
We would like to relax the assumption that the relationship between a cheap measurement and \emph{usual} EE and $\Delta$ES is linear \\

\vspace{0.5cm}

We propose using cubic free knot splines to model the relationship between cheap and \emph{usual}

\begin{itemize}
\item
Allows for a flexible nonlinear relationship
\item
No need to specify number or location of knots
\item
If using Reversible Jump MCMC, incorporates uncertainty in spline selection

\end{itemize}


\end{frame}
%-------


%---------
\begin{frame}
\frametitle{Free Knot Spline Model}

\begin{align*}
  f(Y_{ij}^{EE}|X_i^{EE},Z_i,\boldsymbol{\theta_{yee}}) &\overset{ind}{\sim} N(s(X_i^{EE};\boldsymbol{\beta_{ee}}) + \boldsymbol{\gamma_{ee}}Z_i,\sigma_{\epsilon^{EE}}^2) \\
    f(Y_{ij}^{\Delta ES}|X_i^{\Delta ES},Z_i,\boldsymbol{\theta_{yes}}) &\overset{ind}{\sim} N(s(X_i^{\Delta ES};\boldsymbol{\beta_{\Delta es}}) + \boldsymbol{\gamma_{es}}Z_i,\sigma_{\epsilon^{\Delta ES}}^2) \\
\end{align*}
%vspace{0.3cm}

\begin{align*}
  s(X_i^{EE};\boldsymbol{\beta_{ee}}) &= \sum_{i=1}^{k_{ee}+3} b_{i,ee}({\bf X^{EE}}) \beta_{i,ee} = B_{ee}({\bf X^{EE}}) \boldsymbol{\beta_{ee}}\\
  s(X_i^{\Delta ES};\boldsymbol{\beta_{\Delta es}}) &= \sum_{i=1}^{k_{es}+3} b_{i,es}({\bf X^{\Delta ES}}) \beta_{i,es} = B_{es}({\bf X^{\Delta ES}}) \boldsymbol{\beta_{es}}
\end{align*}

In order to ensure the functions are monotone, constrain $\beta_{1,ee} \leq \beta_{2,ee} \leq ... \leq \beta_{k_{ee}+3,ee}$ 

% \vspace{0.3cm}
% where $B_{ee}()$ and $B_{es}()$ are $n\times (k_{ee}+3)$ and $n \times (k_{es}+3)$ B-spline basis matrices
% 
% \vspace{0.3cm}
% 
% $k_{ee}$ and $k_{es}$ are the number of knots for the EE and $\Delta$ES splines, respectively, which are allowed to vary

\end{frame}
%-----------


\subsection{Estimation}


%---------
\begin{frame}
\frametitle{MCMC Algorithms}

\begin{enumerate}
\item
The Na{\"i}ve model and Linear Measurement Error Model were fit using JAGS
\item
The Spline Measurement Error Model required Reversible Jump MCMC (RJMCMC) and was written in C++ via \texttt{Rcpp}
\end{enumerate}


\end{frame}
%----------


%---------
\begin{frame}
\frametitle{Gibbs Sampler}
Priors were chosen to be conjugate to help simplify the sampler \\

\vspace{0.3cm}

For iteration k=1,...,K, sample from its full conditional:

\begin{enumerate}
%\item
%   \{$\zeta_i^{(k)}:i=1,...,n$\} $|$ $\cdot$  
%  where P($\zeta_i^{(k)}=h$) = $\frac{\pi_h^{(k-1)} N(\mu_h^{(k-1)},\Sigma_h^{(k-1)})}{\sum_{h=1}^{H}\pi_h^{(k-1)} N(\mu_h^{(k-1)},\Sigma_h^{(k-1)})}$ \\
% 
% \item
%  \{$V_h^{(k)}:h=1,...,H-1$ \}$|\cdot \overset{ind}{\sim}$  $Beta(1+n_h,\alpha+n_h')$ \\
% Set $V_H^{(k)}$ = 1 \\
% $n_h = \sum_{i=1}^{n} I(\zeta_i^{(k)}=h)$\\
% $n_h' = \sum_{h'=h+1}^{H} n_{h'}$\\
% 
% 
% \item
% Calculate \{$\pi_i^{(k)}:i=1,...,n$\} $=$ $V_i^{(k)} \prod_{\ell < i} (1-V_{\ell}^{(k)})$


% \item
% $\alpha|\cdot \sim$ $Gamma(a_{\alpha}+n_h+1,b_{\alpha}-\sum_{r=1}^{n_h-1}log(1-V_r))$\\


\item
 %\small 
 \{$\Sigma^{(k)}$\} $|\cdot \overset{ind}{\sim}$ $Inv-Wish(d+n,\psi+({\bf X_{i}^{(k-1)} - \mu^{(k-1)}})'({\bf X_{i}^{(k-1)} - \mu^{(k-1)}}))$ \\

% ${\bf X_{i,h}} \equiv  {\bf X_i} I(\zeta_i^{(k)}=h)$ \\
% ${\bf X_i} = (X_i^{EE},X_i^{\Delta ES})$ \\
% ${\bf \mu_h} = (\mu_{EE,h},\mu_{\Delta ES,h})$



\item
  \{$(\mu_{EE}^{(k)},\mu_{\Delta ES}^{(k)})$ \} $|\cdot \overset{ind}{\sim} N(M_{\mu}',C_{\mu}')$ \\
$C_{\mu}' = (C_{\mu}^{-1} + n \Sigma^{-1(k)})^{-1}$ \\
$M_{\mu}' = C_{\mu}'(C_{\mu}^{-1}M + n \Sigma^{-1(k)} {\bf \bar{X}^{(k-1)}})$ \\
${\bf \bar{X}} = \frac{1}{n}\sum_{i=1}^{n} {\bf X_{i}}$ \\

 

\item
Update ${\bf X_i}$ with a random walk \\
\{${\bf X_i^{(k)}}:i=1,...,n $\}$|\cdot$ for $i=1,...n$ sample ${\bf X_i^*}$ from $N({\bf X_i^{(k)}},C_{X_i})$ \\
Set ${\bf X_i^{(k)}} = {\bf X_i^*}$ with probability $\alpha_{X_i}$, otherwise set ${\bf X_i^{(k)}} = {\bf X_i^{(k-1)}}$ \\

$\alpha_{X_i} = min\left(1, \frac{f({\bf X_i^*}|\cdot)}{f({\bf X_i^{(k-1)}}|\cdot)}  \right)$ \\

\end{enumerate}
\end{frame}
%-----------

%--------------
\begin{frame}

\begin{enumerate}
\setcounter{enumi}{3}
%\small
\item
Update ${\boldsymbol{\beta_{ee}},\boldsymbol{\beta_{es}}},k_{ee},k_{es}, {  r_{ee}, r_{es}}, \boldsymbol{\gamma_{ee}^{}}, \boldsymbol{\gamma_{es}^{}}$ using RJMCMC described next. Calculate $m_{ee}({\bf X^{EE(k)}};\boldsymbol{\beta_{ee}^{(k)}})$ and $m_{es}({\bf X^{\Delta ES(k)}};\boldsymbol{\beta_{es}^{(k)}})$ \\

\vspace{0.2cm}

\item
 $\sigma^{2(k)}_{\epsilon^{EE}} |\cdot \sim IG(a_{yee}+J\times \frac{n}{2},b_{yee}+\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{J}(Y_{ij}^{EE}-m_{ee}(X_i^{EE(k)};\boldsymbol{\beta_{ee}^{(k)}})-\boldsymbol{\gamma_{ee}}^{(k)}Z_i)^2)$ \\
 
\vspace{0.2cm}

\item
 $\sigma^{2(k)}_{\epsilon^{\Delta ES}} |\cdot \sim IG(a_{yes}+J\times \frac{n}{2},b_{yes}+\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{J}(Y_{ij}^{\Delta ES}-m_{es}(X_i^{\Delta ES(k)};\boldsymbol{\beta_{es}^{(k)}})-\boldsymbol{\gamma_{es}}^{(k)}Z_i)^2)$ \\
 
 \vspace{0.2cm}
 
\item
 $\sigma^{2(k)}_{\nu^{EE}} |\cdot \sim IG(a_{wee}+J\times \frac{n}{2},b_{wee}+\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{J}(W_{ij}^{EE}-X_i^{EE(k)})^2)$ \\
 
 \vspace{0.2cm}
 
\item
 $\sigma^{2(k)}_{\nu^{\Delta ES}} |\cdot \sim IG(a_{wes}+J\times \frac{n}{2},b_{wes}+\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{J}(W_{ij}^{\Delta ES}-X_i^{\Delta ES(k)})^2)$ \\
 
 \end{enumerate}


\end{frame}
%----------


%----------
\begin{frame}
\frametitle{RJMCMC}
RJCMCMC was introduced by Green (1995) as a way to ``jump" between different models and dimensions as a means for model determination. Denison introduced a simple and effective implementation of a Bayesian free-knot spline

\vspace{0.3cm}

We extend method of Denison (1998) in three ways:
\begin{enumerate}
\item
The spline covariate is a latent variable that is also sampled from
\item
There are additional linear components to the mean function
\item
We make the modification from DiMatteo (2001) so the likelihood ratio is an approixmation of BIC
\end{enumerate}

\vspace{0.3cm}
Our algorithm is run independently for EE and $\Delta$ES regression functions due to conditional independence, so we will let ($\cdot$) be a placeholder

\end{frame}
%----------

%----------
\begin{frame}
%\small
$\mathcal{A}$=\{$x_i,i=1,...n:x_i$ is not currently a knot or within $\ell+1$ locations of a current knot\}


\begin{enumerate}
\item
Calculate $b_k = c \times min\left(1, \frac{p(k+1)}{p(k)} \right)$ \\
$d_k = c \times min\left(1, \frac{p(k)}{p(k+1)} \right)$ 

\item
Select birth, death, or move step with probabilities $b_k,d_k,1-b_k-d_k$ respectively \\

\item
{\bf Knot Changes} \\
If birth step:\\
%\item
Select a new knot location at random from the set $\mathcal{A}$ and join with current knots $r_{\cdot}^{(k-1)}$ to create the proposed knot locations $r_{\cdot}^{*}$

If death Step:\\
%\item
Sample one knot location from $r_{\cdot}^{(k-1)}$ at random and remove it. 

If move step:\\
%\item
Sample one knot location from $r_{\cdot}^{(k-1)}$ at random, and change it to a new knot location at random from the set $\mathcal{A}$

\end{enumerate}
\end{frame}
%----------

%----------
\begin{frame}

\begin{enumerate}
\setcounter{enumi}{3}
%\small
\item
Calculate the spline basis matrix $B^*_{\cdot}(X^{\cdot(k)})$ using $X^{\cdot(k)}$ and proposed knot locations $r_{\cdot}^{*}$

\item
Calculate proposed spline and linear regression coefficients $\boldsymbol{\beta^*_{\cdot}},\boldsymbol{\gamma^*_{\cdot}}$ by using OLS by regressing $Y^{\cdot}$ on $B^*_{\cdot}(X^{\cdot(k)}) + Z$

\item
Accept proposed knots and coefficients with probability $\alpha_{\cdot}$ \\

Otherwise set $r_{\cdot}^{(k)}=r_{\cdot}^{(k-1)}$, $\boldsymbol{\beta^{(k)}_{\cdot}} =\boldsymbol{\beta^{(k-1)}_{\cdot}}$, $\boldsymbol{\gamma^{(k)}_{\cdot}} =\boldsymbol{\gamma^{(k-1)}_{\cdot}}$\\

\begin{align*}
\alpha_{birth} &= min\left(1, \text{Likelihood ratio}\times \frac{n-Z(k)}{n} \right) \\
\alpha_{death} &= min\left(1, \text{Likelihood ratio}\times \frac{n}{n-Z(k)} \right) \\
\alpha_{move} &= min\left(1, \text{Likelihood ratio}\right) 
\end{align*}

\begin{align*}
Z(k) &= 2(\ell+1) + k_{\cdot}(2\ell+1) \\
k_{\cdot} &= length(r_{\cdot}^{(k-1)}) 
\end{align*}

\item
calculate mean function $m_{\cdot}(X^{\cdot(k)};\boldsymbol{\beta^{(k)}_{\cdot}})$ using spline basis matrix $B'_{\cdot}(X^{\cdot(k)})$ and $r_{\cdot}^{(k)}$


\end{enumerate}

\end{frame}
%----------

\subsection{Simulation Study}

%---------
\begin{frame}
\frametitle{Simulation Study}
We performed a simulation study to assess the performance of the models we discussed in terms of parameter estimation and prediction (for calibration)

\vspace{0.2cm}

Simulated 200 data sets for both 2 and 4 replicates per individual. Number of individuals was set to be 300. Three different measurement errors were used for each set of replicates:

\begin{itemize}
\item
Normal
\item
Skew-Normal
\item
Bimodal (50-50 mixture of two Normals)
\end{itemize}

\vspace{0.2cm}

For each simulated data set, we ran the MCMC for 12,000 iterations, using the first 2000 as burn in

\end{frame}
%-----------


%----------
\begin{frame}
%\begin{landscape}


\begin{table}[ht]
%\centering
%\subcaption{Normal Errors, N{\"a}ive Model}
 \scalebox{0.55}{
\begin{tabular}{r|ll|ll|ll|ll|ll|ll|ll|ll}
  \hline
 & $\sigma_{yee}$ &  & $\sigma_{yes}$ &  & $\gamma_{1,ee}$ &  & $\gamma_{2,ee}$ &  & $\gamma_{3,ee}$ &  & $\gamma_{1,es}$ &  & $\gamma_{2,es}$ &  & $\gamma_{3,es}$ &  \\ 
  \hline
Replicates & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 \\ 
   \hline
Mean Est & 477.65 & 473.42 & 347.49 & 354.85 & 254.67 & 248.66 & 14.88 & 14.03 & -4.14 & -5.29 & -200.53 & -199.39 & 7.91 & 8.31 & -4.94 & -5.13 \\ 
  Std Err & 17.82 & 19.24 & 9.43 & 6.80 & 43.65 & 36.10 & 4.33 & 3.62 & 3.37 & 3.06 & 28.19 & 22.83 & 2.90 & 2.13 & 2.35 & 1.73 \\ 
  Bias & 72.15 & 67.92 & 13.49 & 20.85 & -45.33 & -51.34 & 0.88 & 0.03 & 2.86 & 1.71 & -0.53 & 0.61 & -0.09 & 0.31 & 0.06 & -0.13 \\ 
  Truth & 405.50 & 405.50 & 334.00 & 334.00 & 300.00 & 300.00 & 14.00 & 14.00 & -7.00 & -7.00 & -200.00 & -200.00 & 8.00 & 8.00 & -5.00 & -5.00 \\ 
   \hline
\end{tabular}}

\vspace{1cm}


%\subcaption{Normal Errors, LME}
\scalebox{0.55}{
\begin{tabular}{r|ll|ll|ll|ll|ll|ll|ll|ll|ll|ll}
  \hline
 & $\sigma_{yee}$ &  & $\sigma_{yes}$ &  & $\sigma_{wee}$ &  & $\sigma_{wes}$ &  & $\gamma_{1,ee}$ &  & $\gamma_{2,ee}$ &  & $\gamma_{3,ee}$ &  & $\gamma_{1,es}$ &  & $\gamma_{2,es}$ &  & $\gamma_{3,es}$ &  \\ 
  \hline
Replicates & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 \\ 
   \hline
Mean Est & 444.34 & 446.63 & 320.41 & 338.26 & 255.70 & 255.85 & 69.18 & 71.81 & 249.50 & 240.63 & 14.30 & 13.67 & -4.50 & -5.28 & -199.27 & -198.49 & 7.91 & 8.29 & -4.91 & -5.15 \\ 
  Std Err & 16.84 & 14.22 & 10.76 & 7.53 & 10.74 & 6.33 & 2.27 & 1.56 & 43.44 & 37.02 & 4.25 & 3.60 & 3.38 & 3.04 & 28.31 & 22.96 & 2.91 & 2.12 & 2.30 & 1.71 \\ 
  Bias & 38.84 & 41.13 & -13.59 & 4.26 & 5.70 & 5.85 & -3.68 & -1.05 & -50.50 & -59.37 & 0.30 & -0.33 & 2.50 & 1.72 & 0.73 & 1.51 & -0.09 & 0.29 & 0.09 & -0.15 \\ 
  Truth & 405.50 & 405.50 & 334.00 & 334.00 & 250.00 & 250.00 & 72.86 & 72.86 & 300.00 & 300.00 & 14.00 & 14.00 & -7.00 & -7.00 & -200.00 & -200.00 & 8.00 & 8.00 & -5.00 & -5.00 \\ 
   \hline
\end{tabular}}
\vspace{1cm}


%\subcaption{Normal Errors, BVN}
\scalebox{0.55}{
\begin{tabular}{r|ll|ll|ll|ll|ll|ll|ll|ll|ll|ll}
  \hline
 & $\sigma_{yee}$ &  & $\sigma_{yes}$ &  & $\sigma_{wee}$ &  & $\sigma_{wes}$ &  & $\gamma_{1,ee}$ &  & $\gamma_{2,ee}$ &  & $\gamma_{3,ee}$ &  & $\gamma_{1,es}$ &  & $\gamma_{2,es}$ &  & $\gamma_{3,es}$ &  \\ 
  \hline
Replicates & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 & 2 & 4 \\ 
   \hline
Mean Est & 393.69 & 400.55 & 313.47 & 331.79 & 246.81 & 248.93 & 67.61 & 71.04 & 293.16 & 294.61 & 14.17 & 14.11 & -6.86 & -6.78 & -200.07 & -200.86 & 8.00 & 8.04 & -4.95 & -5.26 \\ 
  Std Err & 11.52 & 8.29 & 12.00 & 8.27 & 8.78 & 5.79 & 2.32 & 1.66 & 36.16 & 26.19 & 3.50 & 2.42 & 2.86 & 2.16 & 26.86 & 19.44 & 2.49 & 2.06 & 2.11 & 1.45 \\ 
  Bias & -11.81 & -4.95 & -20.53 & -2.21 & -3.19 & -1.07 & -5.25 & -1.82 & -6.84 & -5.39 & 0.17 & 0.11 & 0.14 & 0.22 & -0.07 & -0.86 & 0.00 & 0.04 & 0.05 & -0.26 \\ 
  Truth & 405.50 & 405.50 & 334.00 & 334.00 & 250.00 & 250.00 & 72.86 & 72.86 & 300.00 & 300.00 & 14.00 & 14.00 & -7.00 & -7.00 & -200.00 & -200.00 & 8.00 & 8.00 & -5.00 & -5.00 \\ 
   \hline
\end{tabular}}

\vspace{1cm}

%\end{landscape}
\end{table}

\end{frame}
%----------


%-----------
\begin{frame}

\begin{figure}
\centering
\includegraphics[height=8cm,width=10cm]{pmse}
%\caption{Log PMSE for EE Regression (top) and $\Delta$ES Regression (bottom)  faceted by measurement error distribution and number of replicates}
%\label{pmse}
\end{figure}

% \begin{table}[ht]
% \centering
% \begin{tabular}{ll|llll}
%   \hline
%  & Replicates & Naive & Linear & SMEMN & SMEMDP \\ 
%   \hline
% Normal & 2 & 144869.7 & 113975.56 & 71308.89 & - \\ 
%    & 4 & 100096.78 & 75098.25 & 35902.73 & 35602.62 \\ 
%   Skewed & 2 & 138895.41 & 101586.02 & 70058.3 & - \\ 
%    & 4 & 91110.6 & 63178.21 & 35820.27 & 35449 \\ 
%   Bimodal & 2 & 93857.63 & 46486 & 42968.21 & - \\ 
%    & 4 & 84228.86 & 35665.26 & 30936.62 & 28335.85 \\ 
%    \hline
% \end{tabular}
% \caption{PMSE for EE Regression} 
% \label{pmseee}
% \end{table}
% 
% 
% 
% 
% 
% \begin{table}[ht]
% \centering
% \begin{tabular}{ll|llll}
%   \hline
%  & Replicates & Naive & Linear & SMEMN & SMEMDP \\ 
%   \hline
% Normal & 2 & 61567.63 & 43557.94 & 38272.77 & - \\ 
%    & 4 & 36238.56 & 24760.97 & 20654.15 & 20490.67 \\ 
%   Skewed & 2 & 49161.19 & 35783.01 & 31818.48 & - \\ 
%    & 4 & 27917.97 & 19980.43 & 17095.63 & 16969.31 \\ 
%   Bimodal & 2 & 24583.02 & 18758.07 & 17057.83 & - \\ 
%    & 4 & 15772.86 & 11376.04 & 10362.42 & 10263.01 \\ 
%    \hline
% \end{tabular}
% \caption{PMSE for $\Delta$ES Regression} 
% \label{pmsees}
% \end{table}
% 


\end{frame}
%------------


%----------
\begin{frame}
\frametitle{Example of one data set}
  \includegraphics[width=12cm,height=6cm]{predbvnsx.pdf}

\end{frame}
%----------

%--------
% \begin{frame}
%   \includegraphics[width=12cm,height=6cm]{khist.pdf}
% 
% 
% \end{frame}
%--------------

\subsection{Calibration}


%----------
\begin{frame}
\frametitle{Calibration}
The major goal of this model is to be able to give calibration equations for cheap measurements \\

$\Rightarrow$ in the future if no gold standard measurements are taken, can correct cheap measurements using these calibration equations \\

\vspace{0.2cm}

Our goal is to get an estimate of the truth using cheap measurement of the truth y and covariates Z:
\begin{align*}
  X_{calibrated} &= m^{-1}(y-\boldsymbol{\gamma}' Z) 
\end{align*}

\end{frame}
%--------


%-------
% \begin{frame}
% Cannot take inverse of spline (which changes dimensions), so we will find its inverse numerically
% 
% \vspace{0.3cm}
% 
% Use \texttt{optimize} wrt x on the value $|f(x)-y^*|$ where $f()$ represents the regression function and $y^*$ is the observed cheap measurement minus the vector of coefficients $\boldsymbol{\gamma}$ multiplied by the individuals covariate values $Z$
% 
% \vspace{0.3cm}
% 
% Use k draws of linear and spline coefficients, knot locations, and latent variables from MCMC to get k calibrated estimates of x
% 
% 
% \end{frame}
%-------

%--------
\begin{frame}

For r = 1,...R
\begin{enumerate}
\item
Calculate $y_i^* = y_i- \boldsymbol{\gamma}^{(r)'} Z_i$, where $Z_i$ are the covariate values for individual $i$
\item
Use \texttt{optimize} for the function $|m_i(x) - y_i^*|$ to choose the value of $x$ that will minimize the aforementioned criteria, call this $x_{i,calibrated}^{(r)}$. $m_i(x)$ is the predicted value of $y_i$ for the given value $x$ using the MCMC draw for the spline coefficients, latent variables, and knot locations from the $r^{th}$ draw of the chain

\end{enumerate}


\end{frame}
%------------

%--------
\begin{frame}
\frametitle{3 example calibrations}

\begin{table}[ht]
\centering
\begin{tabular}{r|ccc|cc}
  \hline
& Lower & Median & Upper & Observed & Truth \\ 
  \hline
EE & 2574.18 & 2666.00 & 2736.39 & 3028.89 & 2199.25 \\ 
  & 3452.51 & 3525.18 & 3619.08 & 4119.26 & 3588.12 \\ 
  & 2571.99 & 2665.46 & 2744.65 & 2555.86 & 2643.14 \\ 
   \hline  
   $\Delta$ES & 25.15 & 42.35 & 60.57 & 142.30 & 64.17 \\ 
  & -104.21 & -82.93 & -63.90 & -405.74 & -21.08 \\ 
  & -8.41 & 3.91 & 17.83 & 96.06 & -0.48 \\ 
   \hline
\end{tabular}
\caption{95\% credible interval for calibration estimate for cheap measurements for Skewed Errors} 
\label{calibratedee}
\end{table}

\end{frame}
%-------

\subsection{Application}

%--------
\begin{frame}
\frametitle{Data Collection}
%We will be collecting the necessary data on $\sim$30 individuals over the next few months to aid in the development of this model
\begin{columns}
\begin{column}{0.3\textwidth}
  \begin{itemize}
  \item
  30 participants
  \item
  Free living, no treatment
  \item
  M/F
  \item
  Ages 25-35
  \item
  BMI 18-30
  \item
  Convenience sample
\end{itemize}
\end{column}
\begin{column}{0.7\textwidth}
\begin{figure}
\centering
\includegraphics[height=6cm,width=8cm]{studydesign}
\end{figure}
\end{column}
\end{columns}

\end{frame}
%-------


\subsection{Discussion}

%-------
\begin{frame}
\frametitle{Discussion}
We developed a Bayesian semi-parametric measurement error model for energy balance measurements

\begin{itemize}
\item
Constructed a RJMCMC algorithm for free knot splines as a function of latent variables along with a linear component
\item
Developed calibration algorithm to correct for biases in cheap measurements
\item
Simulation study shows predictive power of spline model
\item
Data analysis (coming soon!)
\end{itemize}

\end{frame}
%---------

%--------
% \begin{frame}
% \frametitle{Further Considerations}
% There are a few ways our model can be improved upon/extended
% 
% \begin{itemize}
% \item
% Allowing for non-constant variance in measurement errors
% \item
% Relaxing normality assumption of measurement errors
% \item
% Correctly specifying within person variability for cheap measurements
% \item
% Fully Bayesian estimation of spline (and linear component) parameters
% \end{itemize}
% 
% \end{frame}
%-------

%-------
% \begin{frame}
% \frametitle{We can create energy!}
% 
% \begin{multicols}{2}
% <<eivsee,echo=FALSE,warning=FALSE,fig.width=5,fig.height=5,message=FALSE>>=
% #ebm <- melt(eb[,c("energy","Energy_expenditure")])
% #ggplot(data=ebm) + geom_histogram(aes(x=value,fill=variable),alpha=0.5,position="") + theme_bw()
% 
% df1 <- eb %>% group_by(ID) %>% summarise(chgweight=Weight[length(Weight)]-Weight[1],
%                                          chgfm=TotalFatMass[length(Weight)]-TotalFatMass[1],
%                                     chgffm=TotalFatFreeMass[length(Weight)]-TotalFatFreeMass[1],
%                                     avgei=mean(energy),
%                                     avgee=mean(Energy_expenditure))
% 
% ggplot(data=df1) + geom_histogram(aes(x=avgei,fill="EI"),alpha=0.7,binwidth=200) + geom_histogram(aes(x=avgee,fill="EE"),alpha=0.7,binwidth=200) + xlab("kCals") + theme_bw()
% 
% 
% #ggplot(data=df1) + geom_histogram(aes(x=chgfm),binwidth=2) + xlab("Change in Fat Mass") + theme_bw()
% #ggplot(data=df1) + geom_histogram(aes(x=chgweight),binwidth=2) + xlab("Change in Fat Mass") + theme_bw()
% 
% 
% @
% 
% \columnbreak
% \pause
% <<eivsee2,echo=FALSE,warning=FALSE,fig.width=5,fig.height=5>>=
% ggplot(data=df1) + geom_histogram(aes(x=chgweight),binwidth=3) + xlab("Change in Weight") + theme_bw()
% @
% 
% \end{multicols}
% 
% *Data from Energy Balance Study
% 
% \end{frame}
% 
% \begin{frame}
% \frametitle{Armband vs DLW}
% <<armbandvsdlw,echo=FALSE,fig.height=4.5,fig.width=6>>=
% qplot(x=TDEE,y=Energy_expenditure,data=eb[!is.na(eb$TDEE),],geom="point") + geom_abline(aes(intercept=0,slope=1)) + geom_smooth(method="lm",se=FALSE) + xlab("DLW EE") + ylab("Armband EE") + theme_bw()
% @
% \end{frame}
% 
% %-------------------
% 
% 
% %---------------
% \begin{frame}
% \frametitle{Modeling Energy Balance}
% 
% \end{frame}
% %--------------
% 
% \begin{frame}
% \frametitle{Measurement Methods}
% 
% Measurement of EE and $\Delta$ES is less noisy than EI and true gold standard measurements exist
% 
% \begin{itemize}
% \begin{multicols}{2}
% \item Pedometer
% \item Consumer grade wearables
% \item Sensewear Armband
% \item DLW (gold standard)
% 
% \columnbreak
% \item Body Weight
% \item Calipers
% \item BodPod
% \item Bioelectrical impedence
% \item DXA (gold standard)
% \end{multicols}
% \end{itemize}
% 
% Notice how none of these methods require self report? 
% 
% \end{frame}
% 
% %-----------------
% 
% 
% \section{Measurement Error Models}
% \subsection{Statistical Model}
% 
% %-------------
% \begin{frame}
% \frametitle{Research Goal}
% 
% \begin{block}{Research Outcomes}
% Our overall goal is to provide a cheap, easy, noninvasive \emph{prediction of EI for an individual in free living situations}
% \end{block}
% 
% To achieve our goal:
% 
% \begin{itemize}
% \item
% Statistically assess the measurement error in various instruments of both EE and $\Delta$ES
% \item 
% Calibrate cheaper measures so they provide reasonable accuracy without the expense and expertise required for DLW and DXA
% \end{itemize}
% 
% \end{frame}
% 
% %--------------
% \begin{frame}
% \frametitle{Data Required}
% 
% Because we are assessing the measurement error in these instruments, we need replicate measures of all EE and $\Delta$ES measurements on an individual that accounts for all measurement error.
% 
% This is a little tricky...
% \begin{itemize}
% \item
% %For both cheap measures of EE and DLW, we need two periods of time measuring EE on each individual
% Replicates measurements of EE for an individual
% \item
% %For both cheap measures $\Delta$ES and DXA, we need to measure body composition at the beginning of exercise period and end of exercise period, doing this procedure twice for each individual
% Replicate measurements of $\Delta$ES for an individual
% \item
% Demographic covariates for an individual
% \end{itemize}
% 
% Luckily, we have a wealth of data from the Energy Balance Study to help propose a model and empirically check assumptions.
% 
% \end{frame}
% 
% 
% \subsection{Model Specification}
% 
% \begin{frame}
% We can further specify forms for each component:
% 
% \begin{align}
% Y_{ij}^{EE} &= m_{ee}(X_i^{EE}) + \gamma_{ee}Z_i + \epsilon_{ij}^{EE} \\
% Y_{ij}^{\Delta ES} &= m_{es}(X_i^{\Delta ES}) + \gamma_{es}Z_i + \epsilon_{ij}^{\Delta ES} \\
% W_{ij}^{EE} &= X_i^{EE} + \nu_{ij}^{EE} \\
% W_{ij}^{\Delta ES} &= X_i^{\Delta ES} + \nu_{ij}^{\Delta ES}
% \end{align}
% 
% \end{frame}
% 
% %--------------------%
% \begin{frame}
% \begin{itemize}
% \item
% Because we never can observe $(X_i^{EE},X_i^{\Delta ES})$, it is difficult to say the functional relationship ($m_{ee}$ and $m_{es}$) between it and cheap measurements $Y^{EE}$ and $Y^{\Delta ES}$ 
% 
% \item
% Because of this, we choose to model $m_{ee}$ and $m_{es}$ with B-splines
% \item
% Must specify number of knots $k$ and knot locations $\zeta_1,...\zeta_k$
% \end{itemize}
% 
% \begin{align}
% m_{ee}(X_i^{EE}) &= \sum_{i=1}^{k_{ee}} b_{i,ee}(\zeta_{i,ee}) \beta_{i,ee} = B_{ee}(\zeta_{ee}) \beta_{i,ee} \\
% m_{es}(X_i^{\Delta ES}) &= \sum_{i=1}^{k_{es}} b_{i,es}(\zeta_{i,es}) \beta_{i,es} = B_{es}(\zeta_{es}) \beta_{i,es}
% \end{align}
% 
% We let $k$ and $\zeta_1,...\zeta_k$ vary according to the data
% 
% \end{frame}
% 
% %--------------
% \begin{frame}
% \frametitle{Specifying the Likelihood}
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %get two column
% \begin{align}
% \epsilon_{ij}^{EE} &\overset{ind}{\sim} N(0,\sigma_{i,yee}^2) \\
% \epsilon_{ij}^{\Delta ES} &\overset{ind}{\sim} N(0,\sigma_{i,yes}^2) \\
% \nu_{ij}^{EE} &\overset{ind}{\sim} N(0,\sigma_{i,wee}^2) \\
% \nu_{ij}^{\Delta ES} &\overset{ind}{\sim} N(0,\sigma_{i,wes}^2) 
% \end{align}
% 
% \end{frame}
% 
% %-------------
% \begin{frame}
% \frametitle{Latent Variable Likelihood}
% 
% The final component to have a joint likelihood specified is the bivariate latent variable. Because we \emph{never ever} observe these values, we must specify its distribution carefully
% 
% \begin{align}
% (X_i^{EE}, X_i^{\Delta ES}) &\overset{ind}{\sim} \sum_{h=1}^{\infty} \pi_h N(\mu_h,\Sigma_h) \\
% \pi_h &\overset{ind}{\sim} Stick(\alpha) \\
%  & \sum_{h=1}^{\infty} \pi_h = 1 \\
%  \pi_h &= V_h \prod_{\ell <  h} (1-V_h) \\
%  V_H &= 1\\
%  V_h &\sim Beta(1,\alpha), h<H
% \end{align}
% 
% \end{frame}
% 
% %-------------
% \begin{frame}
% \frametitle{Priors}
% Need to assign priors for unknown parameters 
% \begin{align}
% \boldsymbol{\theta} &= (\{\sigma_{i,yee} \}_{i=1}^{n}, \{\sigma_{i,yes}\}_{i=1}^{n} , \{\sigma_{i,wee}\}_{i=1}^{n} , \\
% & \{\sigma_{i,wes}\}_{i=1}^{n} ,\{\Sigma_{i}\}_{i=1}^{n} , \{\gamma_{i,yee}\}_{i=1}^{p} , \\
% & \{\gamma_{i,yes}\}_{i=1}^{p} , \{\beta_{i,yee}\}_{i=1}^{k_{ee}} , \{\beta_{i,yes}\}_{i=1}^{k_{kes}}, k_{ee}, k_{es}, \\
% & \{\zeta_{i,ee} \}_{i=1}^{k_{ee}},\{\zeta_{i,es} \}_{i=1}^{k_{es}})
% \end{align}
% 
% \end{frame}
% 
% %------------------
% \begin{frame}
% Assume independent priors (for now)
% 
% \begin{multicols}{2}
% \begin{align}
% p(\sigma_{i,yee}) \overset{ind}{\sim} C^+(0,1) \\
% p(\sigma_{i,yes}) \overset{ind}{\sim} C^+(0,1) \\
% p(\sigma_{i,wee}) \overset{ind}{\sim} C^+(0,1) \\
% p(\sigma_{i,wes}) \overset{ind}{\sim} C^+(0,1) \\
% p(\Sigma_i) \overset{ind}{\sim} \text{ Inv-Wish}(I_{2x2},3) 
% \end{align}
% \columnbreak
% \begin{align}
% p(\gamma_{i,ee}) &\overset{ind}{\sim} N(w_{i,ee},B_{i,ee}) \\
% p(\gamma_{i,es}) &\overset{ind}{\sim} N(w_{i,es},B_{i,es}) \\
% p(\beta_{i,ee}) &\overset{ind}{\sim} N(v_{i,ee},C_{i,ee}) \\
% p(\beta_{i,es}) &\overset{ind}{\sim} N(v_{i,es},C_{i,es}) \\
% p(k_{ee}) &{\sim} Poi(a_{ee}) \\
% p(k_{es}) &{\sim} Poi(a_{es}) 
% \end{align}
% \end{multicols}
% \begin{align}
% p(\zeta_1,...,\zeta_{k_{ee}}|k_{ee}) &\sim DUnif(x_1^{EE},...,x_n^{EE}) \\
% p(\zeta_1,...,\zeta_{k_{es}}|k_{es}) &\sim DUnif(x_1^{\Delta ES},...,x_n^{\Delta ES})
% \end{align}
% 
% Priors likely to change as we elicit expert information and use of past data
% 
% \end{frame}
% 
% \subsection{Estimation}
% 
% %---------------
% \begin{frame}
% \frametitle{Estimation}
% Since we are taking a Bayesian approach, the posterior distribution $p(\boldsymbol{\theta}|Y,W,Z)$ gives us everything we need for inference
% 
% \begin{itemize}
% \item
% Using Bayes Rule: 
% \begin{align}
% p(\boldsymbol{\theta}|Y,W,Z) &= \frac{p(Y,W|\boldsymbol{\theta},Z) p(\boldsymbol{\theta})}{\int p(Y,W,\boldsymbol{\theta}|Z) d\boldsymbol{\theta}}
% \end{align}
% \item 
% Integral is impossible to evaluate analytically, use MCMC to simulate draws from joint posterior
% \item
% Will use Gibbs Sampler to update parameters 
% \item
% Reversible Jump MCMC step necessary for B-splines since number of knots $k$ and knot locations $\zeta_1,...\zeta_k$ are random variables and therefore dimension of posterior is allowed to change
% \item
% Implement in R/C++
% \end{itemize}
% 
% \end{frame}
% 
% %-------------
% \subsection{Model Assessment and Inference}
% 
% %-------------
% \begin{frame}
% \frametitle{Model Assessment and Comparason}
% We will assess the fit of our model through the use of the posterior predictive distributions and relevant discrepancy measures $D()$
% 
% \begin{align}
%   p(Y^*|W,Y,Z) &= \int \int p(Y^*|\boldsymbol{\theta},X,Z) p(\boldsymbol{\theta}, X|Y,W) d\boldsymbol{\theta} dX \\
%   p(W^*|W,Y,Z) &= \int \int p(W^*|\boldsymbol{\theta},X,Z) p(\boldsymbol{\theta}, X|Y,W) d\boldsymbol{\theta} dX \\
%   p(X^*|W,Y,Z) &= \int \int p(X^*|\boldsymbol{\theta}) p(\boldsymbol{\theta}, X|Y,W) d\boldsymbol{\theta} dX
% \end{align}
% 
% For each simulated replicate data set (for each $Y,W,X$) calculate $D()$. Compare to $D()$ from true data
% 
% \end{frame}
% 
% %----------------
% \begin{frame}
% \frametitle{Model Comparason}
% Although I presented only one specific model here, there are simplifying (and more complicating) assumptions we could (and will) make. To compare models we can use:
% 
% \begin{itemize}
% \item
% DIC
% \item 
% Bayes Factors
% \item
% PMSE of EI --- this is not straightforward
% \item
% Parsimony and Practical Interpretation
% \end{itemize}
% 
% \end{frame}
% 
%----------------

\section{Modeling MVPA}
%-------------------
\begin{frame}
To Assess Compliance with \emph{2008 Physical Activity Guidelines}:

\vspace{0.4cm}
\huge A Bayesian two-part model with measurement error: Assessing adult moderate to vigorous activity and compliance to 2008 Physical Activity Guidelines

\end{frame}
%------------------

\subsection{Introduction}

%----------------
\begin{frame}
\frametitle{2008 Physical Activity Guidelines}
Because of the many benefits linked to prevention and treatment of numerous diseases \\%such as cardiovascular disease, diabetes, hypertension, depression, etc \\

The Department of Health and Human Services Recommends Adults 18-65 participate each week in at least:

\begin{itemize}
\item
150 Minutes of Moderate Physical Activity 
\item
75 Minutes of Vigorous Physical Activity
\item
75-150 Minutes during some combindation of Moderate and Vigorous Physical Activity (MVPA)
\item
Full body resistance training two days per week
\item
Most benefits occur when activity is performed in at least 10 minute \emph{bouts}
\end{itemize}

\vspace{0.3cm}

What proportion of adults adhere to these guidlines? Are there differences among different demographics?

\end{frame}
%---------------


%-----------
\begin{frame}
\frametitle{Physical Activity Measurement Survery (PAMS)}
2 year studying starting in 2009 collecting 2 days of physical activity data via Sensewear Armband and 24 Hour Recall on adults in four Iowa counties

\begin{itemize}
\item
Measurements of physical activity are over 24 hours
\item
Replicate measurements taken 2-3 weeks apart
\item
Minute by minute data from armband (in MET-minutes)
\item
Survery weights needed 
\item
Measurement error involved
\end{itemize}

\end{frame}
%-----------


%-----------
\begin{frame}
%\frametitle{}

Definition of a bout \\

\begin{itemize}
\item
$Y_{1ij}$ : Number of bouts individual $i$ during trial $j$ participated in per day
\item
$Y_{2ij}$ : Total MET-minutes individual $i$ during trial $j$ accrued in at least 10 minute bouts minues 30*$Y_{1ij}$ per day (total excess MET-minutes)
\item
$Z_i$ : Observed demographic variables for individual $i$
\item
$X_{1i}$ Individual $i$'s expected number of bouts per day
\item
$X_{2i}$ Individual $i$'s expced total excess minutes per day
\item
$X_{3i}$ Individual $i$'s expected total minutes in MVPA per day ($= 30*X_{1i}+X_{2i}$)
\end{itemize}

\end{frame}
%----------

\subsection{Exchangeability}

%_--------
\begin{frame}
\frametitle{Exchangeability within person for $Y_1$}
\begin{columns}
\begin{column}{0.3\textwidth}
Bowker's test of symmetry: p-value = 0.1474
\end{column}
\begin{column}{0.7\textwidth}
\includegraphics[height=6cm, width=8cm]{y1exch}
\end{column}
\end{columns}

\end{frame}
%--------



%_--------
\begin{frame}
\frametitle{Exchangeability within person for $Y_2$}
Total excess MET-minutes depends on number of bouts, need to account for it as well as eliminate individual effects

\begin{align*}
Y_{2i1}-Y_{2i2} &= \beta_0 + \beta_1(Y_{1i1}-Y_{1i2}) + \beta_2(Weekend_{i1}-Weekend_{i2}) + \epsilon_i \\
\epsilon_i &\overset{iid}{\sim} N(0,\sigma^2)
\end{align*}

\begin{table}[!htbp] \centering 
\begin{tabular}{l|lll}
\hline
Coefficient & Estimate & Std Error & P-value \\
\hline
$\beta_0$ & 23.305 & 11.10 & 0.036 \\
$\beta_1$ & 86.827 & 3.489 & $<$0.0001 \\
$\beta_2$ & 22.145 & 18.425 & 0.230 \\
\hline
\end{tabular} 
\end{table} 


Excluding individuals with $Y_2 >$ 2300 (5 out of 1085 individuals), the estimate for trial effect  reduces to 13.62 with a p-value of 0.124, while other results remain similar

\end{frame}
%--------

\subsection{Methods}

%--------
\begin{frame}
\frametitle{Modeling Number of Bouts}
First thought is a Poisson-Gamma mixture with mean of Gamma as a regression on covariates ${\bf Z}$ (use BMI,age,gender,smoker)

\begin{align*}
	Y_{1ij} | X_{1i} &\overset{ind}{\sim} \text{Poisson}(X_{1i}) \\
	X_{1i} | \eta,\mu_i &\overset{ind}{\sim} \text{Gamma} \left( \eta,\frac{\eta}{\mu_i} \right) \\
	\mu_i &= e^{Z_i' \boldsymbol{\beta}} \\
	p(\eta) &\sim \text{Gamma}(a_1,a_2) \\
	p(\boldsymbol{\beta}) &\sim N \left( {\bf 0_k}, \frac{1}{v} I_{k \times k} \right)
	%p(\zeta) &\sim \text{Gamma}(b_1,b_2) 
\end{align*}

\end{frame}
%---------


%--------
\begin{frame}
\frametitle{Assessing Overdispersion}

\centering
\includegraphics{y1ppmarg}

\includegraphics{y1ppcond}


\end{frame}
%--------

%--------
\begin{frame}
\frametitle{Two-Part Model for $Y_2$}
After an appropriate adjustment for day effect, we model $Y_2$ as

\begin{align*}
\begin{split}
	Y_{2ij}|X_{2i}, X_{1i} &\overset{ind}{\sim} (1-\pi_{ij}(\boldsymbol{\alpha})) \delta_0(Y_{2ij}) + \pi_{ij}(\boldsymbol{\alpha}) LN(\mu_{y,i} (\boldsymbol{\beta_y}), \sigma_y^2)\\
	X_{2i}|X_{1i}, Z_i &\overset{ind}{\sim} LN(\mu_{x,i} (\boldsymbol{\beta_x}), \sigma_x^2)
\end{split}
\end{align*}

\begin{align*}
\pi_{ij}(\boldsymbol{\alpha}) &= \Phi({\bf X_i}' \boldsymbol{\alpha}) 
\end{align*}

\begin{align*}
 \mu_{y,i}(\boldsymbol{\beta_y}) &=  E(\text{log } Y_{2ij}|Y_{2ij} > 0) = {\bf X_i}'\boldsymbol{\beta_y}
\end{align*} 

\begin{align*}
 \mu_{x,i}(\boldsymbol{\beta_x}) &=  E(\text{log } X_{2ij}) = {\bf Z_i}'\boldsymbol{\beta_x} + X_{1i} \gamma
\end{align*} 


\end{frame}
%--------

%-------
\begin{frame}
\frametitle{Model Assessment}

\begin{align*}
	T_{1}({\bf Y_1}) &=  \sum_{i=1}^{n} I(Y_{1i1} = Y_{1i2}) \\
	T_2({\bf Y_2}) &= \sum_{i=1}^{n} \sum_{j=1}^{j(i)} I(Y_{2ij} = 0) \\
	T_3({\bf Y_2}) &= \sum_{i=1}^{n}  I(Y_{2i1} = Y_{2i2} = 0) \\
	T_4({\bf Y_2}) &= \frac{1}{N} \sum_{i=1}^{n} \sum_{j=1}^{j(i)} I \left( Y_{2ij} > \frac{450}{7} \right) \\
	T_5({\bf Y_1,Y_2}) &= \beta_1 \text{ coefficient from regression assessing exchangebability } 
\end{align*}

\end{frame}
%-------


%-------
\begin{frame}
\frametitle{Estimating Probability of Compliance on Average}

For $\ell$ from $\ell=1,2,...,L$ do:
\begin{enumerate}
\item
Sample $\boldsymbol{\theta}^{(\ell)}$ from the posterior distribution $p(\boldsymbol{\theta}|{\bf Y,Z})$
\item
Simulate ${ X_{1i}^{*(\ell)}}$ from $p(X_{1i}|\boldsymbol{\theta}^{(\ell)},Z_i)$ for $i=1,...,n$
\item
Simulate ${ X_{2i}^{*(\ell)}}$ from $p(X_{2i}|\boldsymbol{\theta}^{(\ell)},X_{1i}^{*(\ell)},Z_i)$ for $i=1,...,n$
\item
Calculate $X_{3i}^{*(\ell)}= 30 X_{1i}^{*(\ell)} + X_{2i}^{*(\ell)}$ for $i=1,...,n$
\item
Calculate $p^{(\ell)} = \frac{1}{n} \sum_{i=1}^{n} I \left( X_{3i}^{*(\ell)} \geq \frac{450}{7} \right) $
\end{enumerate}

\end{frame}
%------

\end{document}